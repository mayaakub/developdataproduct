# Create a deck as a 13x4 matrix which is easy to verify by eye.
deck <- sapply(suits, function(suit)paste(values, suit, sep=":"))
# Verify.
deck
# Note the value of a card is its row index (if Aces are low.)
# Select n cards from a deck at random without replacement.
hand <- function(n, deck)sample(deck, n, replace=FALSE)
# Deal k hands of n cards each as a kxn matrix.
deal <- function(k, n, deck){
# Select kxn cards at random without replacement.
temp <- hand(k*n, deck)
# Reshape selections into a kxn matrix. Since R
# fills by column, this is like dealing the cards
# out in circular order around the table. (Not that
# it makes any difference since the selection process
# is a random permutation of the deck anyway.)
matrix(temp, k, n)
}
deal
deck
hand
hand(1,deck)
hand(4,deck)
x <- c(0,2,2,0,0); y <- c( 0,0,1,1,0)
plot(x, y, lwd = 3, frame = FALSE, type = "l")
segments(0,0,2,1,lwd=3)
plot(x, y, lwd = 3, frame = FALSE, type = "l")
segments(0,0,2,1,lwd=3)
#polygon(c(.5,1.5,1.5,.5,.5),c(0,0,.75,.25,0),lwd= 3, col = "lightblue")
polygon(c(0,1.6,1.6,0),c(0,0,.8,0),lwd=3,col="lightblue")
mypdf <- function(x){x/2}
#polygon(c(0,.6,.6,0),c(0,0,.3,0),lwd=3, col="lightblue")
dice_fair <- c(1/6,1/6,1/6,1/6,1/6,1/6)
dice_high <- c(1/21,2/21,3/21,4/21,5/21,6/21)
dice_low <- c(6/21,5/21,4/21,3/21,2/21,1/21)
expect_dice <- function(pmf){ mu <- 0; for (i in 1:6) mu <- mu + i*pmf[i]; mu}
dice_sqr <- c(1,4,9,16,25,36)
edh <- expect_dice(dice_high)
edl <- expect_dice(dice_low)
edh
edl
swirl()
library(ggplot2)
dat <- data.frame(
x = c(sample(1 : 6, nosim, replace = TRUE),
apply(matrix(sample(1 : 6, nosim * 2, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 3, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 4, replace = TRUE),
nosim), 1, mean)
),
size = factor(rep(1 : 4, rep(nosim, 4))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.25, colour = "black")
g <- g + facet_grid(. ~ size)
print(g)
dat <- data.frame(
x = c(sample(1 : 6, nosim, replace = TRUE),
apply(matrix(sample(1 : 6, nosim * 2, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 3, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 4, replace = TRUE),
nosim), 1, mean)
),
size = factor(rep(1 : 4, rep(nosim, 4))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.25, colour = "black")
g <- g + facet_grid(. ~ size)
print(g)
library(ggplot2)
dat <- data.frame(
x = c(sample(1 : 6, nosim, replace = TRUE),
apply(matrix(sample(1 : 6, nosim * 2, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 3, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 4, replace = TRUE),
nosim), 1, mean)
),
size = factor(rep(1 : 4, rep(nosim, 4))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.25, colour = "black")
g <- g + facet_grid(. ~ size)
print(g)
library(ggplot2)
dat <- data.frame(
x = c(sample(1 : 6, nosim, replace = TRUE),
apply(matrix(sample(1 : 6, nosim * 2, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 3, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 4, replace = TRUE),
nosim), 1, mean)
),
size = factor(rep(1 : 4, rep(nosim, 4))))
dat <- data.frame(
x = c(sample(1 : 6, nosim, replace = TRUE),
apply(matrix(sample(1 : 6, nosim * 2, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 3, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 4, replace = TRUE),
nosim), 1, mean)
),
size = factor(rep(1 : 4, rep(nosim, 4))))
dice_fair <- c(1/6,1/6,1/6,1/6,1/6,1/6)
dice_high <- c(1/21,2/21,3/21,4/21,5/21,6/21)
dice_low <- c(6/21,5/21,4/21,3/21,2/21,1/21)
expect_dice <- function(pmf){ mu <- 0; for (i in 1:6) mu <- mu + i*pmf[i]; mu}
dice_sqr <- c(1,4,9,16,25,36)
edh <- expect_dice(dice_high)
edl <- expect_dice(dice_low)
spop <- c(1,4,7,10,13)
sam0 <- c(1,4)
sam1 <- c(1,7)
sam2 <- c(1,10)
sam3 <- c(1,13)
sam4 <- c(4,7)
sam5 <- c(4,10)
sam6 <- c(4,13)
sam7 <- c(7,10)
sam8 <- c(7,13)
sam9 <- c(10,13)
allsam <- matrix(c(sam0,sam1,sam2,sam3,sam4,sam5,sam6,sam7,sam8,sam9),nrow=10,ncol=2,byrow=TRUE)
smeans <- apply(allsam,1,mean)
library(ggplot2)
nosim <- 10000; n <- 10
dat <- data.frame(
x = c(rnorm(nosim), apply(matrix(rnorm(nosim * n), nosim), 1, mean)),
what = factor(rep(c("Obs", "Mean"), c(nosim, nosim)))
)
np <- ggplot(dat, aes(x = x, fill = what)) + geom_density(size = 2, alpha = .2);
print(np)
library(ggplot2)
dat <- data.frame(
x = c(sample(1 : 6, nosim, replace = TRUE),
apply(matrix(sample(1 : 6, nosim * 2, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 3, replace = TRUE),
nosim), 1, mean),
apply(matrix(sample(1 : 6, nosim * 4, replace = TRUE),
nosim), 1, mean)
),
size = factor(rep(1 : 4, rep(nosim, 4))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.25, colour = "black")
g <- g + facet_grid(. ~ size)
print(g)
# some plots
par(mfrow = c(1, 2))
plot(c(-0.25, 0, 0, 1, 1, 1.25), c(0, 0, 1, 1, 0, 0), type = "l", lwd = 3, frame = FALSE, xlab="", ylab = ""); title('f(t)')
plot(c(-0.25, 0, 1, 1, 1.25), c(0, 0, 1, 0, 0), type = "l", lwd = 3, frame = FALSE, xlab="", ylab = ""); title('t f(t)')
# some plots
par(mfrow = c(1, 2))
plot(c(-0.25, 0, 2, 2, 2.25), c(0, 0, 1, 0, 0), type = "l", lwd = 3, frame = FALSE, xlab="", ylab = ""); title('f(t)')
my_x <- seq(0,2,by=.1)
my_y <- my_x^2/2
plot(my_y ~ my_x, type = "l", lwd = 3, frame = FALSE, xlab="", ylab = ""); title('t f(t)')
abline(v=2.0, lwd=3)
myfunc <- function(x){x^2/2}
sessionInfo()
library(bigr)
bigr.connect(host="10.5.133.183",user="bigr",password="Passw0rd")
is.bigr.connected()
airline <- bigr.frame(bigr.env$TEXT_FILE,"airline_demo.csv",coltypes=ifelse(1:29 %in% c(9,11,17,18,23), "character","integer"),header=TRUE, na.string="NA",useMapReduce=FALSE)
str(airline)
airlineFiltered <- airline[,c("Month","DayofMonth","DayOfWeek","CRSDepTime","Distance","ArrDelay")]
airlineFiltered$Delay <- ifelse(airlineFiltered$ArrDelay > 15, "High", ifelse(airlineFiltered$ArrDelay < 5, "Low", "Medium"))
airlineMatrix <- bigr.transform(airlineFiltered,outData="airlinef.sample.matrix",transformPath="airline.sample.transform")
airlineMatrix <- bigr.transform(airlineFiltered,outData="airlinef.sample.matrix",transformPath="airline.sample.transform")
airlineMatrix <- bigr.transform(airlineFiltered,outData="airlinef.sample.matrix",transformPath="airline.sample.transform")
str(airlineMatrix)
bigr.univariateStats(airlineMatrix)
bigr.bivariateStats(airlineMatrix,cols1=c("Month","DayofMonth","DayOfWeek","CRSDepTime","Distance"),cols2=c("ArrDelay"))
samples <- bigr.sample(airlineMatrix,perc=c(0.7,0.3))
train <- samples[[1]]
test <- samples[[2]]
nrow(train) / nrow(airlineMatrix)
nrow(test) / nrow(airlineMatrix)
lm <- bigr.lm(ArrDelay ~ ., data=train, directory="lm.airline")
coef(lm)
pred <- predict(lm, test, "lm.airline.preds")
pred
lm <- bigr.lm(ArrDelay ~ ., data=train, directory="lm.airline")
coef(lm)
pred <- predict(lm, test, "lm.airline.preds")
pred
lm <- bigr.lm(ArrDelay ~ ., data=train, directory="lm.airline")
coef(lm)
pred <- predict(lm, test, "lm.airline.preds")
pred
svmModel <- bigr.svm(formula=Delay ~ ., data=train, directory="svm.airline")
coef(svmModel)
predSVM <- predict(svmModel, test, "svm.preds.airline", returnScores=T)
predSVM
svmModel <- bigr.svm(formula=Delay ~ ., data=train, directory="svm.airline")
coef(svmModel)
predSVM <- predict(svmModel, test, "svm.preds.airline", returnScores=T)
predSVM
str(airline)
barplot(summary(airline$Year))
unique(airline$Year)
barplot(summary(factor(airline$Year)))
barplot(summary(level(airline$Year)))
airline$year
airline$Year
summary(airline$Year)
barplot(summary(airline$Year))
barplot(airline$Year)
plot(airline$Year)
airline$Year
View(airline)
tapply(airline$Year,sum)
tapply(airline$Year,count)
?tapply
tapply(airline$UniqueCarrier,airline$Year,sum)
tapply(airline$UniqueCarrier,airline$Year,sum)
attache(airline)
attach(airline)
tapply(UniqueCarrier,Year,sum)
tapply("UniqueCarrier",Year,sum)
tapply(Year,UniqueCarriersum)
tapply(Year,UniqueCarrier,sum)
tapply(ArrDelay,Year,sum)
airline
head (airline)
airline$UniqueCarrier
sapply(UniqueCarrier,sum)
lapply(UniqueCarrier, sum)
unique(UniqueCarrier)
tapply(ArrTime, Year, sum)
tapply(as.vector(ArrTime), as.vector(Year), sum)
tapply(as.vector(ArrTime), Year, sum)
tapply(as.numeric(ArrTime), as.vector(Year), sum)
bigr
?bigr
?bigr
barplot(summary(Deptime))
attach(airline)
View(airline)
barplot(summary(DepTime))
barplot(Arrtime)
barplot(ArrTime)
barplot(as.vector(ArrTime))
barplot(as.numeric(ArrTime))
barplot(as.numeric(as.vector(ArrTime)))
barplot(as.numeric(as.vector(Year)))
?summary
library(bigr)
barplot(bigr.summary(airline$Year))
?bigr
library(bigr)
?bigr.summary
?base.summary
summary(Year)
bigr.summary(Year)
ig
bigr.connect(host="10.5.133.183",user="bigr",password="Passw0rd")
library(bigr)
bigr.connect(host="10.5.133.183",user="bigr",password="Passw0rd")
is.bigr.connected()
airline <- bigr.frame(bigr.env$TEXT_FILE,"airline_demo.csv",coltypes=ifelse(1:29 %in% c(9,11,17,18,23), "character","integer"),header=TRUE, na.string="NA",useMapReduce=FALSE)
str(airline)
install.packages("caret")
install.packages("C50")
install.packages("kernlab")
install.packages("e1071")
quit();
source('C:/Users/09234/Desktop/Coursera Data Science/08 Practical Machine Learning/ML_Quiz#2Q#5.R')
install.packages("AppliedPredictiveModeling")
source('C:/Users/09234/Desktop/Coursera Data Science/08 Practical Machine Learning/ML_Quiz#2Q#5.R')
source('C:/Users/09234/Desktop/Coursera Data Science/08 Practical Machine Learning/ML_Quiz#2Q#5.R')
print(A2)
print(A1)
print(A2)
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("rpart")
library(pgmm)
data(olive)
dim(olive)
head(olive)
olive <- olive[,-1]
treeModel <- train(Area ~ ., data=olive, method="rpart2")
treeModel
newdata <- as.data.frame(t(colMeans(olive)))
predict(treeModel, newdata)
library(pgmm)
data(olive)
dim(olive)
head(olive)
olive <- olive[,-1]
olive
dim(loive)
dim(olive)
treeModel <- train(Area ~ ., data=olive, method="rpart2")
library(caret)
treeModel <- train(Area ~ ., data=olive, method="rpart2")
treeModel
newdata <- as.data.frame(t(colMeans(olive)))
predict(treeModel, newdata)
install.packages("zoo")
install.packages("ggvis")
library(plyr)
library(dplyr)
library(data.table)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
confusionMatrix(predRf, vowel.test$y)$overall[1]
confusionMatrix(predGBM, vowel.test$y)$overall[1]
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
head(pred)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy # Agreement Accuracy: 0.6569579
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
# fit rf predictor relating the factor variable y
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
# RF Accuracy: 0.6060606
confusionMatrix(predRf, vowel.test$y)$overall[1]
# GBM Accuracy: 0.530303
confusionMatrix(predGBM, vowel.test$y)$overall[1]
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
head(pred)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy # Agreement Accuracy: 0.6569579
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData <- data.frame(diagnosis, predictors)
inTrain <- createDataPartition(adData$diagnosis, p=3/4)[[1]]
training <- adData[inTrain, ]
testing <- adData[-inTrain, ]
dim(adData) # 333 131
# head(adData)
set.seed(62433)
fitRf <- train(diagnosis ~ ., data=training, method="rf")
fitGBM <- train(diagnosis ~ ., data=training, method="gbm")
fitLDA <- train(diagnosis ~ ., data=training, method="lda")
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
# Stack the predictions together using random forests ("rf")
fit <- train(diagnosis ~., data=pred, method="rf")
predFit <- predict(fit, testing)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGBM, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength,
p=3/4)[[1]]
training <- concrete[inTrain, ]
testing <- concrete[-inTrain, ]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength,
p=3/4)[[1]]
training <- concrete[inTrain, ]
testing <- concrete[-inTrain, ]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
fit
plot.enet(fit$finalModel, xvar="penalty", use.color=T) # Cement
library(lubridate)  # For year() function below
library(forecast)
dat <- read.csv("./data/gaData.csv")
training <- dat[year(dat$date) < 2012, ]
testing <- dat[(year(dat$date)) > 2011, ]
tstrain <- ts(training$visitsTumblr)
fit <- bats(tstrain)
fit
pred <- forecast(fit, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
# How many of the testing points is the true value within the
# 95% prediction interval bounds?
prop.table(table(predComb$in95))[2] # 0.9617021
install.packages("forecast")
library(lubridate)  # For year() function below
library(forecast)
dat <- read.csv("./data/gaData.csv")
training <- dat[year(dat$date) < 2012, ]
testing <- dat[(year(dat$date)) > 2011, ]
tstrain <- ts(training$visitsTumblr)
fit <- bats(tstrain)
fit
pred <- forecast(fit, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
# How many of the testing points is the true value within the
# 95% prediction interval bounds?
prop.table(table(predComb$in95))[2] # 0.9617021
library(lubridate)  # For year() function below
library(forecast)
dat <- read.csv("./data/gaData.csv")
if (!file.exists("gaData.csv")) {
file.url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
download.file(file.url,destfile='gaData.csv')
}
if (!file.exists("gaData.csv")) {
file.url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
download.file(file.url,destfile='gaData.csv')
}
dat <- read.csv("gaData.csv")
training <- dat[year(dat$date) < 2012, ]
testing <- dat[(year(dat$date)) > 2011, ]
tstrain <- ts(training$visitsTumblr)
fit <- bats(tstrain)
fit
pred <- forecast(fit, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
# How many of the testing points is the true value within the
# 95% prediction interval bounds?
prop.table(table(predComb$in95))[2] # 0.9617021
set.seed(3523)
library(AppliedPredictiveModeling)
library(e1071)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength, p=3/4)[[1]]
training <- concrete[inTrain, ]
testing <- concrete[-inTrain, ]
set.seed(325)
fit <- svm(CompressiveStrength ~., data=training)
# OR another way
# fit <- train(CompressiveStrength ~. data=training, method="svmRadial")
pred <- predict(fit, testing)
acc <- accuracy(pred, testing$CompressiveStrength)
acc
acc[2] # RMSE 6.715009
library(bigr)
bigr.connect(host="10.5.133.183",user="bigr",password="Passw0rd")
is.bigr.connected()
library(bigr)
bigr.connect(host="10.5.133.183",user="bigr",password="Passw0rd")
is.bigr.connected()
library(slidify)
library(devtools)
library(slidify)
install_github('slidify','ramnathv')
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
install_github('ramnathv/slidify')
install_github('ramnathv/slidifyLibraries')
library(slidify)
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_2')
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_2')
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_2')
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_2')
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_2')
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_2')
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_2')
sessionInfo()
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_2')
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_2')
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_2')
sessionInfo()
installed.packages()
installed.packages()[c(1:10),]
sessioninfo()
sessionInfo()
getwd()
quit()
getwd()
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_3c-RenderUI')
str(DataBase)
shiny::runApp('C:/Users/09234/Desktop/Coursera Data Science/MyWork/DataProductProject_3c-RenderUI')
setwd("C:/Users/09234/developdataproduct/shinyApp")
library(shinyapps)
shiny::runApp('C:/Users/09234/developdataproduct/shinyApp')
shiny::deployApp('C:/Users/09234/developdataproduct/shinyApp')
shinyapps::deployApp('C:/Users/09234/developdataproduct/shinyApp')
shiny::runApp()
